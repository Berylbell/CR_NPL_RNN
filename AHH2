# -*- coding: utf-8 -*-
"""
Created on Sat Jun  6 19:06:47 2020

@author: berylroll

script to download transcripts from CR wiki page
"""

import requests
import re
import io
import os 
from bs4 import BeautifulSoup
import trnscrptClean as tc

def get_page (url= 'https://criticalrole.fandom.com/wiki/Transcripts'):
    #download a webpage and preprocess the html
    res = requests.get(url)
    html_page = res.content
    soup = BeautifulSoup(html_page, 'html.parser')
    text = soup.find_all(text=True)
    output = ''
    blacklist = [
    	'[document]',
    	'noscript',
    	'header',
    	'html',
    	'meta',
    	'head', 
    	'input',
    	'script',
    	# there may be more elements you don't want, such as "style", etc.
    ]
    
    for t in text:
    	if t.parent.name not in blacklist:
    		output += '{} '.format(t)
    
    return output

def get_eps_names(main_page):
    #finds all the ep names from season 2 and returns them in a list
    main_page = main_page[main_page.find("Campaign 2: The Mighty Nein Edit")+1:main_page.find("Specials Edit")]
    names = re.findall(r'\"(.+?)\"',main_page)
    return names
    

def download_all(names):
    #make urls for all eps transcripts
    wiki= 'https://criticalrole.fandom.com/wiki/'
    tran= '/Transcript'
    try:
        os.remove("Transcripts\\transcript2_master.txt")
    except:
        print("Masterfile didnt exist")
    for i in range(0,len(names)):
        #replace spaces with _ and take out first and last spaces
        #print(names[i])
        url = names[i].replace(' ', '_')[1:-1]        
        url = wiki + url +tran

        #download the page
        output = get_page(url)
        output = preprocess_wiki(output)
        
        #input('count.')
        try:
            os.remove("Transcripts\\transcript2_"+str(i+1)+".txt")
        except:
            print("File "+str(i+1)+" didnt exist")
            
        with io.open("Transcripts\\transcript2_"+str(i+1)+".txt", "a", encoding="utf-8") as myfile:
            myfile.write(output)
        with io.open("Transcripts\\transcript2_master.txt", "a", encoding="utf-8") as myfile:
            myfile.write(output)
            
        #[speaker, dia, speak_text] = tc.seperate_Chara(output)
        #print(set(speaker))
        #input('cont')
 
def preprocess_wiki(output):
    
    haspost = output.ccount(" Post-Show Edit")
    hasbreak = output.count(" Break Edit ")
    #Split out the times when the show is actually going on: 
    end = "NewPP"
    if(haspost == 1):
        if(hasbreak ==1):
            #given break, split one way
            output = output[output.find("Part I Edit"):output.find("Break Edit")]+output[output.find("Part II Edit"):output.find("NewPP")]
        elif(hasbreak==0):
            #given no break, split another 
            output = output[output.find("Part I Edit"):output.find("NewPP")]
    else:
    #Remove headers
    output = output.replace("Pre-Show Edit ",'')
    output = output.replace(" Part II Edit ",'')
    output = output.replace(" Part I Edit ",'')
    output = output.replace(" Break Edit ",'')
    output = output.replace(" NewPP ",'')

    
main_page = get_page()
names = get_eps_names(main_page)
download_all(names)
